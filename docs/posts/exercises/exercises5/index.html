<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>Datastories Hub: Exercises 5</title>

<meta property="description" itemprop="description" content="Becoming a Data Detective: Uncovering Racial Bias &amp; more"/>

<link rel="canonical" href="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-11-23"/>
<meta property="article:created" itemprop="dateCreated" content="2020-11-23"/>
<meta name="article:author" content="Ralf Martin"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Datastories Hub: Exercises 5"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Becoming a Data Detective: Uncovering Racial Bias &amp; more"/>
<meta property="og:url" content="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"/>
<meta property="og:image" content="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/p03dq1gg.jpg"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Datastories Hub"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Datastories Hub: Exercises 5"/>
<meta property="twitter:description" content="Becoming a Data Detective: Uncovering Racial Bias &amp; more"/>
<meta property="twitter:url" content="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"/>
<meta property="twitter:image" content="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/p03dq1gg.jpg"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Datastories Hub: Exercises 5"/>
<meta name="citation_fulltext_html_url" content="https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"/>
<meta name="citation_online_date" content="2020/11/23"/>
<meta name="citation_publication_date" content="2020/11/23"/>
<meta name="citation_author" content="Ralf Martin"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","categories","editor_options","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Exercises 5"]},{"type":"character","attributes":{},"value":["Becoming a Data Detective: Uncovering Racial Bias & more"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Ralf Martin"]},{"type":"character","attributes":{},"value":["https://mondpanther.github.io/wwwmondpanther/"]}]}]},{"type":"character","attributes":{},"value":["2020-11-23"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","css","includes"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["../../webex.css"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["after_body"]}},"value":[{"type":"character","attributes":{},"value":["../../webex.js"]}]}]}]},{"type":"character","attributes":{},"value":["Exercises"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["chunk_output_type"]}},"value":[{"type":"character","attributes":{},"value":["inline"]}]},{"type":"character","attributes":{},"value":["https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"]},{"type":"character","attributes":{},"value":["https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["exercises5_files/bowser-1.9.3/bowser.min.js","exercises5_files/distill-2.2.21/template.v2.js","exercises5_files/jquery-1.11.3/jquery.min.js","exercises5_files/webcomponents-2.0.0/webcomponents.js","p03dq1gg.jpg"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<style type="text/css">
#twitter {
  float: right; 
  width: 50%;
}
#scheduler {
  float: left; 
  width: 50%;
}
@media screen and (max-width: 600px) {
  embed {
    height: 250px;
  }
  #twitter, #scheduler { width: 100%; }
}

/* styles for solveme */
.solveme { border: 2px dotted red; }
.solveme.correct { border: 2px solid blue; }
/* styles for hidden solutions */
.solution {
    height: 2em;
    overflow-y: hidden;
    padding: 0.2em;
}
.solution.open {
    height: auto;
    background-color: rgba(0, 0, 0, 0.1);
    border-radius: 5px;
}
.solution button {
    height: 1.5em;
    margin-bottom: 0.5em;
}
.solution pre.sourceCode {
    border-color: green;
}

</style>
<!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="..\..\webex.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Exercises 5","description":"Becoming a Data Detective: Uncovering Racial Bias & more","authors":[{"author":"Ralf Martin","authorURL":"https://mondpanther.github.io/wwwmondpanther/","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-11-23T00:00:00.000+00:00","citationText":"Martin, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../../index.html" class="title">Datastories Hub</a>
</div>
<div class="nav-right">
<a href="../../../index.html" aria-label="Home">
<i class="fa fa-home" aria-hidden="true"></i>
</a>
<a href="../../../listexercises.html">Exercises</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Exercises 5</h1>
<p><p>Becoming a Data Detective: Uncovering Racial Bias &amp; more</p></p>
</div>

<div class="d-byline">
  Ralf Martin <a href="https://mondpanther.github.io/wwwmondpanther/" class="uri">https://mondpanther.github.io/wwwmondpanther/</a> 
  
<br/>2020-11-23
</div>

<div class="d-article">
<div class="layout-chunk" data-layout="l-body">
<p><img src="p03dq1gg.jpg" width="80%" data-distill-preview=1 /></p>
</div>
<h1 id="exercise-5.1">Exercise 5.1</h1>
<p>For this question we will use a dataset from a randomized experiment conducted by Marianne Bertrand and Sendhil Mullainathan, who sent 4,870 fictitious resumes out to employers in response to job adverts in Boston and Chicago in 2001. The resumes differ in various attributes including the names of the applicants, and different resumes were randomly allocated to job openings. Some of the names are distinctly white sounding and some distinctly black sounding. The researchers collecting these data were interested to learn whether black sounding names obtain fewer callbacks for interviews than white names. Load the data set bm.dta.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(haven)
  data &lt;- read_dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AABua74TH54FcmOsAs0ayMY5a/bm.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
   education         ofjobs         yearsexp      computerskills  
 Min.   :0.000   Min.   :1.000   Min.   : 1.000   Min.   :0.0000  
 1st Qu.:3.000   1st Qu.:3.000   1st Qu.: 5.000   1st Qu.:1.0000  
 Median :4.000   Median :4.000   Median : 6.000   Median :1.0000  
 Mean   :3.618   Mean   :3.661   Mean   : 7.843   Mean   :0.8205  
 3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.: 9.000   3rd Qu.:1.0000  
 Max.   :4.000   Max.   :7.000   Max.   :44.000   Max.   :1.0000  
      call             female           black    
 Min.   :0.00000   Min.   :0.0000   Min.   :0.0  
 1st Qu.:0.00000   1st Qu.:1.0000   1st Qu.:0.0  
 Median :0.00000   Median :1.0000   Median :0.5  
 Mean   :0.08049   Mean   :0.7692   Mean   :0.5  
 3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:1.0  
 Max.   :1.00000   Max.   :1.0000   Max.   :1.0  </code></pre>
</div>
<h3 id="part-a">Part (a)</h3>
<p>The data set contains two dummy variables (0-1 variables) for gender (female) and whether the applicant has computer skills (computerskills). Tabulate these variables by black.</p>
<p>Do gender and computer skills look balanced – i.e. random - across race groups? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  table(data$female,data$black)</code></pre>
<pre><code>
   
       0    1
  0  575  549
  1 1860 1886</code></pre>
<pre class="r"><code>
  prop.table(table(data$female,data$black))</code></pre>
<pre><code>
   
            0         1
  0 0.1180698 0.1127310
  1 0.3819302 0.3872690</code></pre>
</div>
<p>There are many more female than male CVs (i.e. about 38%+38%=76% of the sample are female). However, gender seems not all correlated with race; i.e. the split between black and non black is virtually half for both men and women.</p>
<p>A similar pattern emerges for computer skills and racial background.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  prop.table(table(data$computerskills,data$black))</code></pre>
<pre><code>
   
             0          1
  0 0.09568789 0.08377823
  1 0.40431211 0.41622177</code></pre>
</div>
</div>
<h3 id="part-b">Part (b)</h3>
<p>Do a similar tabulation for education and the number of jobs previous held (ofjobs). These variables take on 5 and 7 different values, respectively.</p>
<p>Does education and the number of previous jobs look balanced across race groups? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<p>To be sure, run a regression. Are the differences significant? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p>
<div class="solution">
<button>
Hint:
</button>
<p>You can tabulate to eye-ball proportions but if you want to be sure that there aren’t small discrepancies, it is always best to run a regression.</p>
</div>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  table(data$education,data$black)</code></pre>
<pre><code>
   
       0    1
  0   18   28
  1   18   22
  2  142  132
  3  513  493
  4 1744 1760</code></pre>
<pre class="r"><code>
  prop.table(table(data$education,data$black))</code></pre>
<pre><code>
   
              0           1
  0 0.003696099 0.005749487
  1 0.003696099 0.004517454
  2 0.029158111 0.027104723
  3 0.105338809 0.101232033
  4 0.358110883 0.361396304</code></pre>
<pre class="r"><code>
  table(data$ofjobs,data$black)</code></pre>
<pre><code>
   
      0   1
  1  54  56
  2 347 357
  3 726 703
  4 800 811
  5 258 275
  6 243 221
  7   7  12</code></pre>
<pre class="r"><code>
  prop.table(table(data$ofjobs,data$black))</code></pre>
<pre><code>
   
              0           1
  1 0.011088296 0.011498973
  2 0.071252567 0.073305955
  3 0.149075975 0.144353183
  4 0.164271047 0.166529774
  5 0.052977413 0.056468172
  6 0.049897331 0.045379877
  7 0.001437372 0.002464066</code></pre>
</div>
There is no clear relation between education/number of jobs and race either. If we are worried about small discrepancies we could also run a regression to test if differences are significant:
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
 data$ofjobs=factor(data$ofjobs)
 summary(lm(black~ofjobs,data))</code></pre>
<pre><code>
Call:
lm(formula = black ~ ofjobs, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.63158 -0.50341 -0.05394  0.49659  0.52371 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.509091   0.047690  10.675   &lt;2e-16 ***
ofjobs2     -0.001989   0.051281  -0.039    0.969    
ofjobs3     -0.017138   0.049492  -0.346    0.729    
ofjobs4     -0.005677   0.049291  -0.115    0.908    
ofjobs5      0.006857   0.052381   0.131    0.896    
ofjobs6     -0.032798   0.053043  -0.618    0.536    
ofjobs7      0.122488   0.124264   0.986    0.324    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.5002 on 4863 degrees of freedom
Multiple R-squared:  0.0007238, Adjusted R-squared:  -0.0005091 
F-statistic: 0.587 on 6 and 4863 DF,  p-value: 0.741</code></pre>
</div>
<p>Hence the different job categories are individually (and jointly) insignificant. Note an OLS regression always reports a test that all coefficients are jointly not significant (the p-value of 0.741 reported at the end of the output).</p>
</div>
<h3 id="part-c">Part (c)</h3>
<p>Look at the mean and standard deviation for the variable for years of experience (yearsexp) separately for black and whites.</p>
<p>Does this variable look similar by race? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mean(data$yearsexp[data$black==1])</code></pre>
<pre><code>
[1] 7.829569</code></pre>
<pre class="r"><code>
  sd(data$yearsexp[data$black==1])</code></pre>
<pre><code>
[1] 5.010764</code></pre>
<pre class="r"><code>
  mean(data$yearsexp[data$black==0])</code></pre>
<pre><code>
[1] 7.856263</code></pre>
<pre class="r"><code>
  sd(data$yearsexp[data$black==0])</code></pre>
<pre><code>
[1] 5.079228</code></pre>
</div>
</div>
<h3 id="part-d">Part (d)</h3>
<p>What do you make of the overall results on resume characteristics?</p>
<p>Is it important to figure out if these variables look similar across the race groups? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select> Think why or why not.</p>
<div class="solution">
<button>
Answer:
</button>
<p>If there was any evidence of a systematic relationship between race and any of those characteristics we could potentially be in trouble when simply comparing interview call backs for different race groups. Any differences found could simply due to those other factors rather than racial bias by employers.</p>
</div>
<h3 id="part-e">Part (e)</h3>
<p>The variable of interest on the data set is the variable call, which indicates a call back for an interview.</p>
<p>What percentage of people receive a call back (rounded up to 2 decimal places)? <input class='solveme nospaces' size='4' data-answer='["8.05"]'/></p>
<p>Do you find differences in call back rates by race? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  prop.table(table(data$call))</code></pre>
<pre><code>
         0          1 
0.91950719 0.08049281 </code></pre>
<pre class="r"><code>
  prop.table(table(data$call,data$black))</code></pre>
<pre><code>
   
             0          1
  0 0.45174538 0.46776181
  1 0.04825462 0.03223819</code></pre>
<pre class="r"><code>
  prop.table(table(data$call,data$black),2) </code></pre>
<pre><code>
   
             0          1
  0 0.90349076 0.93552361
  1 0.09650924 0.06447639</code></pre>
<pre class="r"><code>
  # Note that by specifying 2 we report proportions by column (if you specify 1 it reports proportions by rows)</code></pre>
</div>
<p>We see that most CVs never received a call back (i.e. overall only 8.05% received a call back).</p>
</div>
<h3 id="part-f">Part (f)</h3>
<p>What do you conclude from the results of the Bertand and Mullainathan experiment?</p>
<p>Are black people as likely to receive a call back as white people? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>There seems to be a clear difference between the races. Whereas for white people call back rates where above average (9.65%) they were below average for black people (6.45%) suggesting a racial bias by employers.</p>
</div>
<h1 id="exercise-5.2">Exercise 5.2</h1>
<p>Lets use the dataset from the experiment by Bertand and Mullainathan (bm.dta) again.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  data &lt;- read_dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AABua74TH54FcmOsAs0ayMY5a/bm.dta?dl=1&quot;)</code></pre>
</div>
<h3 id="part-a-1">Part (a)</h3>
<p>Develop a regression to examine if the difference in interview callbacks between black and white “sounding” CVs is significantly different.</p>
<p>What is the code for the simplest linear regression (we call this model “mod”)? mod &lt;- <input class='solveme nospaces ignorecase' size='19' data-answer='["lm(call~black,data)"]'/></p>
<p>Whata is the code for the simplest logit regression (we call this model “mod2”)? mod2 &lt;- <input class='solveme nospaces ignorecase' size='36' data-answer='["glm(call~black,data,family=binomial)"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod &lt;- lm(call~black,data)
  mod2 &lt;- glm(call~black,data,family=binomial)</code></pre>
</div>
</div>
<h3 id="part-b-1">Part (b)</h3>
<p>Execute both regression models in turn.</p>
<p>Are the results similar? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>Linear regression:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod &lt;- lm(call~black,data)
  summary(mod)</code></pre>
<pre><code>
Call:
lm(formula = call ~ black, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.09651 -0.09651 -0.06448 -0.06448  0.93552 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.096509   0.005505  17.532  &lt; 2e-16 ***
black       -0.032033   0.007785  -4.115 3.94e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.2716 on 4868 degrees of freedom
Multiple R-squared:  0.003466,  Adjusted R-squared:  0.003261 
F-statistic: 16.93 on 1 and 4868 DF,  p-value: 3.941e-05</code></pre>
</div>
<p>Alternatively we can use logit:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod2 &lt;- glm(call~black,data,family=binomial)
  summary(mod2)</code></pre>
<pre><code>
Call:
glm(formula = call ~ black, family = binomial, data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.4505  -0.4505  -0.3651  -0.3651   2.3416  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -2.23663    0.06863 -32.590  &lt; 2e-16 ***
black       -0.43818    0.10732  -4.083 4.45e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2726.9  on 4869  degrees of freedom
Residual deviance: 2709.9  on 4868  degrees of freedom
AIC: 2713.9

Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>
  library(margins)
  margins(mod2) </code></pre>
<pre><code>
    black
 -0.03232</code></pre>
</div>
<p>Note that the marginal effects using logit are very similar to the linear model.</p>
</div>
<h1 id="exercise-5.3">Exercise 5.3</h1>
<p>For this question, download the data set cps.dta, which comes from the responses to the monthly US Current Population Survey (CPS) in 2001, a large labour market survey. This data set contains data on 8,891 individuals living in Boston and Chicago. We want to use these data to compare the skills of real live blacks and whites (as opposed to made up CVs), and their employment outcomes and see how they differ from the findings in the exercises involving the bm.dta dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AAAOb_v-Y2V0NN4-rxahZjl4a/cps.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
 employed        black            female          education   
 No  :1942   Min.   :0.0000   Min.   :0.0000   HSD     : 980  
 Yes :6931   1st Qu.:0.0000   1st Qu.:0.0000   HSG     :2358  
 NA&#39;s:  18   Median :0.0000   Median :1.0000   some col:2460  
             Mean   :0.1508   Mean   :0.5161   col+    :3093  
             3rd Qu.:0.0000   3rd Qu.:1.0000                  
             Max.   :1.0000   Max.   :1.0000                  
    yearsexp    
 Min.   : 0.00  
 1st Qu.:11.00  
 Median :21.00  
 Mean   :20.94  
 3rd Qu.:30.00  
 Max.   :59.00  </code></pre>
</div>
<h3 id="part-a-2">Part (a)</h3>
<p>The data set contains a variable education, which takes on four values (high school dropouts, high school graduates, some college, and college degree and more). Use the education variable to create a new dummy for resumes indicating some college or more (i.e. those in the “some college” category plus those in the college and more category).</p>
<p>What percentage of respondents has at least some college education (rounded up to the nearest percent)? <input class='solveme nospaces' size='2' data-answer='["63"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  HE &lt;- as.integer(data$education==&quot;some col&quot; | data$education==&quot;col+&quot;)
  mean(HE)</code></pre>
<pre><code>
[1] 0.6245642</code></pre>
<pre class="r"><code>
  sum(HE)</code></pre>
<pre><code>
[1] 5553</code></pre>
<pre class="r"><code>
  #adding HE variable to dataframe
  data[&quot;HE&quot;] &lt;- HE
  summary(data)</code></pre>
<pre><code>
 employed        black            female          education   
 No  :1942   Min.   :0.0000   Min.   :0.0000   HSD     : 980  
 Yes :6931   1st Qu.:0.0000   1st Qu.:0.0000   HSG     :2358  
 NA&#39;s:  18   Median :0.0000   Median :1.0000   some col:2460  
             Mean   :0.1508   Mean   :0.5161   col+    :3093  
             3rd Qu.:0.0000   3rd Qu.:1.0000                  
             Max.   :1.0000   Max.   :1.0000                  
    yearsexp           HE        
 Min.   : 0.00   Min.   :0.0000  
 1st Qu.:11.00   1st Qu.:0.0000  
 Median :21.00   Median :1.0000  
 Mean   :20.94   Mean   :0.6246  
 3rd Qu.:30.00   3rd Qu.:1.0000  
 Max.   :59.00   Max.   :1.0000  </code></pre>
</div>
<p>Note that nearly 63% of the sample have some college education.</p>
</div>
<h3 id="part-b-2">Part (b)</h3>
<p>First make employed into dichotomous variable and then conduct a regression analysis of the chances of being employed for people with different racial backgrounds.</p>
<p>Are black people significantly less likely to be employed? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<p>If yes, what is the percentage difference (rounded to the nearest percentage point)? <input class='solveme nospaces' size='1' data-answer='["9"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  #modify employed as a dichotomous variable
  table(data$employed)</code></pre>
<pre><code>
  No  Yes 
1942 6931 </code></pre>
<pre class="r"><code>
  table(as.integer(data$employed))</code></pre>
<pre><code>
   1    2 
1942 6931 </code></pre>
<pre class="r"><code>
  data[&quot;employed2&quot;] &lt;- as.integer(data$employed)-1
  summary(data)</code></pre>
<pre><code>
 employed        black            female          education   
 No  :1942   Min.   :0.0000   Min.   :0.0000   HSD     : 980  
 Yes :6931   1st Qu.:0.0000   1st Qu.:0.0000   HSG     :2358  
 NA&#39;s:  18   Median :0.0000   Median :1.0000   some col:2460  
             Mean   :0.1508   Mean   :0.5161   col+    :3093  
             3rd Qu.:0.0000   3rd Qu.:1.0000                  
             Max.   :1.0000   Max.   :1.0000                  
                                                              
    yearsexp           HE           employed2     
 Min.   : 0.00   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:11.00   1st Qu.:0.0000   1st Qu.:1.0000  
 Median :21.00   Median :1.0000   Median :1.0000  
 Mean   :20.94   Mean   :0.6246   Mean   :0.7811  
 3rd Qu.:30.00   3rd Qu.:1.0000   3rd Qu.:1.0000  
 Max.   :59.00   Max.   :1.0000   Max.   :1.0000  
                                  NA&#39;s   :18      </code></pre>
<pre class="r"><code>
  mod1 &lt;- lm(employed2~black,data)
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ black, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.7949  0.2051  0.2051  0.2051  0.2964 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.794879   0.004748  167.40  &lt; 2e-16 ***
black       -0.091286   0.012237   -7.46 9.48e-14 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4122 on 8871 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.006234,  Adjusted R-squared:  0.006122 
F-statistic: 55.65 on 1 and 8871 DF,  p-value: 9.481e-14</code></pre>
</div>
<p>A regression of employment status on a dummy indicating a black racial background suggests that black people are significantly less likely to be employed. The difference amounts to 9.1 percentage points.</p>
</div>
<h3 id="part-c-1">Part (c)</h3>
<p>Conduct a regression analysis of the chances of having college education for people with different racial backgrounds.</p>
<p>What is the percentage difference (rounded to the nearest percentage point)? <input class='solveme nospaces' size='2' data-answer='["11"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod2 &lt;- lm(HE~black,data)
  summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = HE ~ black, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.6420 -0.6420  0.3580  0.3580  0.4735 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.641987   0.005553 115.607  &lt; 2e-16 ***
black       -0.115514   0.014299  -8.078 7.41e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4825 on 8889 degrees of freedom
Multiple R-squared:  0.007288,  Adjusted R-squared:  0.007177 
F-statistic: 65.26 on 1 and 8889 DF,  p-value: 7.414e-16</code></pre>
</div>
<p>The difference in the probability of having higher education between people with non black and black background is 11 percentage points.</p>
</div>
<h3 id="part-d-1">Part (d)</h3>
<p>On the basis of your evidence what can you conclude about racial discrimination in the US labor market?</p>
<p>Do we see a open-and-shut case of racial bias here? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p>
<p>Think of the potential caveats and alternative explanations.</p>
<p>What analysis could you undertake to address some of these caveats? <select class='solveme' data-answer='["Run a regression holding education level constant"]'> <option></option> <option>None, it’s fine as it is</option> <option>Run a regression holding education level constant</option> <option>Include parental income data and run a regression holding this variable constant</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>The result in (b) is consistent with racial bias. However, from (c) we also see that people with black background tend to have less college education and college education is another major driver of being employed:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  summary(lm(employed2~HE,data))</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ HE, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8206  0.1794  0.1794  0.2845  0.2845 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.715486   0.007109  100.64   &lt;2e-16 ***
HE          0.105124   0.008996   11.69   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4104 on 8871 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.01516,   Adjusted R-squared:  0.01505 
F-statistic: 136.5 on 1 and 8871 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>Hence, far from implying a racial issue, the result in (b) could simply reflect employers preference for more highly educated workers. We can examine this by doing the analysis in (b) separately for workers with different educational attainment; i.e.:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod3 &lt;- lm(employed2~black,data,subset=data$HE==1)
  summary(mod3)</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ black, data = data, subset = data$HE == 
    1)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8260  0.1740  0.1740  0.1740  0.2162 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.825961   0.005513 149.809  &lt; 2e-16 ***
black       -0.042177   0.015479  -2.725  0.00645 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.3835 on 5539 degrees of freedom
  (12 observations deleted due to missingness)
Multiple R-squared:  0.001339,  Adjusted R-squared:  0.001158 
F-statistic: 7.425 on 1 and 5539 DF,  p-value: 0.006453</code></pre>
<pre class="r"><code>
  mod4 &lt;- lm(employed2~black,data,subset=data$HE==0)
  summary(mod4)</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ black, data = data, subset = data$HE == 
    0)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.7392 -0.6145  0.2608  0.2608  0.3855 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.739163   0.008636   85.59  &lt; 2e-16 ***
black       -0.124629   0.019814   -6.29 3.59e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4487 on 3330 degrees of freedom
  (6 observations deleted due to missingness)
Multiple R-squared:  0.01174,   Adjusted R-squared:  0.01144 
F-statistic: 39.56 on 1 and 3330 DF,  p-value: 3.588e-10</code></pre>
</div>
<p>The results suggest that for either group there is a significant racial gap when it comes to being employed. Note that the effect is considerably stronger for less educated workers. Hence this re-enforces the hypothesis that there is discrimination against workers with black background which is un-related to their productivity in the workplace.</p>
<p>However, there might be further caveats: our simple regression cannot account for the quality of the college education which can vary considerably and might vary systematically along racial lines. Furthermore, an important driver for a good education and for various other skills might have to do with parental income and status. Again, this is likely to vary systematically along racial lines.</p>
<p>While it is interesting to ask if employers discriminate above and beyond what could be expected on the basis of education and skill of workers – which is what we were implicitly doing above - we might also be concerned about the overall impact of racial background on labor market outcomes which includes initially different educational outcomes. Hence, depending on our interest we might be primarily focused on the effect of race holding education fixed or we might be focused on the overall effect.</p>
</div>
<h1 id="exercise-5.4">Exercise 5.4</h1>
<p>Consider once more the cps.dta dataset. In exercise 3 we argued that not accounting for education might bias our estimate of the impact of racial background. We then examined the issue by looking at college educated vs not college educated workers separately.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AAAOb_v-Y2V0NN4-rxahZjl4a/cps.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
 employed        black            female          education   
 No  :1942   Min.   :0.0000   Min.   :0.0000   HSD     : 980  
 Yes :6931   1st Qu.:0.0000   1st Qu.:0.0000   HSG     :2358  
 NA&#39;s:  18   Median :0.0000   Median :1.0000   some col:2460  
             Mean   :0.1508   Mean   :0.5161   col+    :3093  
             3rd Qu.:0.0000   3rd Qu.:1.0000                  
             Max.   :1.0000   Max.   :1.0000                  
    yearsexp    
 Min.   : 0.00  
 1st Qu.:11.00  
 Median :21.00  
 Mean   :20.94  
 3rd Qu.:30.00  
 Max.   :59.00  </code></pre>
</div>
<h3 id="part-a-3">Part (a)</h3>
<p>First add the HE (higher education) variable to the data frame and modify the employed variable as a dichotomous variable calling it “employed2”. Can you propose an alternative strategy using a multivariate regression approach?</p>
<p>What is the command for a linear regression with two variables (we call this model “mod1”)? mod1 &lt;- <input class='solveme nospaces ignorecase' size='27' data-answer='["lm(employed2~black+HE,data)"]'/></p>
<p>What is the command for a slightly more complex linear regression with two variables and their interaction (we call this model “mod2”)? mod2 &lt;- <input class='solveme nospaces ignorecase' size='36' data-answer='["lm(employed2~black+HE+black*HE,data)"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  #adding HE variable to dataframe
  data[&quot;HE&quot;] &lt;- as.integer(data$education==&quot;some col&quot; | data$education==&quot;col+&quot;)
  #modify employed as a dichotomous variable
  data[&quot;employed2&quot;] &lt;- as.integer(data$employed)-1
  mod1 &lt;- lm(employed2~black+HE,data)
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ black + HE, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8307  0.1693  0.1693  0.2694  0.3491 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.730628   0.007462  97.917  &lt; 2e-16 ***
black       -0.079705   0.012198  -6.534 6.75e-11 ***
HE           0.100094   0.009008  11.111  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4094 on 8870 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.01988,   Adjusted R-squared:  0.01966 
F-statistic: 89.94 on 2 and 8870 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>
  mod2 &lt;- lm(employed2~black+HE+black*HE,data)
  summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = employed2 ~ black + HE + black * HE, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8260  0.1740  0.1740  0.2608  0.3855 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.739163   0.007876  93.849  &lt; 2e-16 ***
black       -0.124629   0.018070  -6.897 5.68e-12 ***
HE           0.086798   0.009831   8.829  &lt; 2e-16 ***
black:HE     0.082451   0.024481   3.368  0.00076 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.4092 on 8869 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.02113,   Adjusted R-squared:  0.0208 
F-statistic: 63.81 on 3 and 8869 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<h3 id="part-b-3">Part (b)</h3>
<p>There are potentially two models you might have used in part (a) one that implies that the effect of race is the same for both educational groups or one that implies the effect of race is different for different educational groups.</p>
<p>Which model is more appropriate? <select class='solveme' data-answer='["The one with the interaction term"]'> <option></option> <option>The one without the interaction term</option> <option>The one with the interaction term</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>The test for the interaction coefficient is significant. That suggest the negative “black” effect is significatly less strong for higher educated workers; i.e. it’s important to have the more complicated model with interaction term.</p>
<p>Some alternative ways of testing include:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  anova(mod2,mod1)</code></pre>
<pre><code>
Analysis of Variance Table

Model 1: employed2 ~ black + HE + black * HE
Model 2: employed2 ~ black + HE
  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1   8869 1484.9                                  
2   8870 1486.8 -1   -1.8992 11.344 0.0007603 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>
  # or alternatively
  library(lmtest)
  waldtest(mod2,mod1)</code></pre>
<pre><code>
Wald test

Model 1: employed2 ~ black + HE + black * HE
Model 2: employed2 ~ black + HE
  Res.Df Df      F    Pr(&gt;F)    
1   8869                        
2   8870 -1 11.344 0.0007603 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>
  # or alternatively
  coeftest(mod2)</code></pre>
<pre><code>
t test of coefficients:

              Estimate Std. Error t value  Pr(&gt;|t|)    
(Intercept)  0.7391627  0.0078761 93.8488 &lt; 2.2e-16 ***
black       -0.1246287  0.0180702 -6.8969 5.677e-12 ***
HE           0.0867985  0.0098305  8.8295 &lt; 2.2e-16 ***
black:HE     0.0824513  0.0244806  3.3680 0.0007603 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<h3 id="part-c-2">Part (c)</h3>
<p>On the basis of your regressions in (b), what is the racial gap for college educated people in percentage points (to 1 decimal place)? <input class='solveme nospaces' size='3' data-answer='["4.3"]'/></p>
<p>What is the racial gap for non college educated people in percentage points (to 1 decimal place)? <input class='solveme nospaces' size='4' data-answer='["12.5"]'/></p>
<p>Think of how this compares to your findings in Exercise 5.3.</p>
<div class="solution">
<button>
Answer:
</button>
<p>College educated black people have a 12.5-8.2=4.3 percentage points lower likelihood of being employed. For non college educated the propbability is 12.5 percentage points lower; i.e. short of rounding error this corresponds to exactly what we found in exercise 3 as well.</p>
</div>
<h1 id="exercise-5.5">Exercise 5.5</h1>
<p>Use wage1.dta and examine once more the relationship between education and wages.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  library(car)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AADZ4MZhDDk9R8sFSjBvmcRma/WAGE1.DTA?dl=1&quot;)</code></pre>
</div>
<p>Would you say the relationship is different for men and women? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>We can allow for a separate response for women by including a female dummy and also interact the education variable with gender status. Note that you can do this by creating the various variables first. A faster way is to use R’s ability to create new variables as part of the model description of the lm command:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod2 &lt;- lm(wage~educ+educ*female,data)
  summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = wage ~ educ + educ * female, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.1611 -1.8028 -0.6367  1.0054 15.5258 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.20050    0.84356   0.238    0.812    
educ         0.53948    0.06422   8.400 4.24e-16 ***
female      -1.19852    1.32504  -0.905    0.366    
educ:female -0.08600    0.10364  -0.830    0.407    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.186 on 522 degrees of freedom
Multiple R-squared:  0.2598,    Adjusted R-squared:  0.2555 
F-statistic: 61.07 on 3 and 522 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>
  linearHypothesis(mod2,c(&quot;educ:female=0&quot;,&quot;female=0&quot;))</code></pre>
<pre><code>
Linear hypothesis test

Hypothesis:
educ:female = 0
female = 0

Model 1: restricted model
Model 2: wage ~ educ + educ * female

  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1    524 5980.7                                  
2    522 5300.2  2    680.51 33.511 2.031e-14 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<p>Note that this leads to “female” parameters that individually are not significant. However, a joint significance test reveals that the variables combined have explanatory power; i.e. the low significance in the regression is likely a consequence of co-linearity of the female and female*education variables. We can also see this by just regressing on a female dummy which leads to a highly significant (and negative) effect (as we have seen before).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
    summary( lm(wage~educ+female:educ,data))</code></pre>
<pre><code>
Call:
lm(formula = wage ~ educ + female:educ, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.3234 -1.7394 -0.6856  1.0567 15.5795 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.28526    0.65041  -0.439    0.661    
educ         0.57548    0.05039  11.421  &lt; 2e-16 ***
educ:female -0.17764    0.02183  -8.138 2.95e-15 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.186 on 523 degrees of freedom
Multiple R-squared:  0.2586,    Adjusted R-squared:  0.2558 
F-statistic: 91.23 on 2 and 523 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>You might consequently ask, which is the right model? There are several considerations:</p>
<ol type="1">
<li>Work with the more general model even though the coefficients are individually not significant what matters is that they jointly matter.</li>
<li>Consider theory: is it more plausible that there are other factors that imply that women have a lower wage whatever they do or is it more plausible that the impact of education is radically different? The former seems more plausible to me but you are free to differ.</li>
</ol>
</div>
<h1 id="exercise-5.6">Exercise 5.6</h1>
<p>Use the production2.dta dataset. This data set contains data on output (value added) and inputs at the industry level for 459 industries in 1958 and 1993.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  library(lmtest)
  library(car)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AAB8jv5xON_4OlZG50sj2l-xa/production2.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
      sic            year           emp             vship         
 Min.   :2011   Min.   :58.0   Min.   :  0.10   Min.   :    24.9  
 1st Qu.:2437   1st Qu.:58.0   1st Qu.: 10.30   1st Qu.:   323.3  
 Median :3221   Median :75.5   Median : 19.30   Median :  1026.6  
 Mean   :3039   Mean   :75.5   Mean   : 35.59   Mean   :  3768.3  
 3rd Qu.:3560   3rd Qu.:93.0   3rd Qu.: 40.05   3rd Qu.:  3493.3  
 Max.   :3999   Max.   :93.0   Max.   :511.40   Max.   :167825.8  
    matcost              vadd             energy       
 Min.   :     8.1   Min.   :    9.1   Min.   :   0.20  
 1st Qu.:   155.4   1st Qu.:  155.7   1st Qu.:   3.20  
 Median :   510.9   Median :  492.0   Median :  13.85  
 Mean   :  1997.6   Mean   : 1773.3   Mean   :  71.80  
 3rd Qu.:  1726.9   3rd Qu.: 1699.1   3rd Qu.:  53.15  
 Max.   :120458.8   Max.   :47272.0   Max.   :3780.60  
      cap         
 Min.   :    3.7  
 1st Qu.:  292.2  
 Median :  682.6  
 Mean   : 1974.8  
 3rd Qu.: 1711.6  
 Max.   :61909.7  </code></pre>
</div>
<p>Suppose the relationship between output and inputs is described by a Cobb-Douglas production function: <span class="math display">\[Y_{i} = AK_{\alpha}^{i}L_{\beta}^{i}\]</span></p>
<p>where <span class="math inline">\(Y_{i}\)</span> is a measure of output, <span class="math inline">\(K_{i}\)</span> is the capital stock, and <span class="math inline">\(L_{i}\)</span> is employment. Answer all questions for the year 1958 only.</p>
<h3 id="part-a-4">Part (a)</h3>
<p>Transform the production function to a linear equation by taking logs. Estimate the parameters and by an OLS regression using total value added as your measure of output.</p>
<p>What coefficient on the log(emp) variable (rounded to 3 decimal places)? <input class='solveme nospaces' size='5' data-answer='["0.697"]'/></p>
<p>What coefficient on the log(cap) variable (rounded to 3 decimal places)? <input class='solveme nospaces' size='5' data-answer='["0.276"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<p>We can regress the following linear regression model:</p>
<p><span class="math display">\[\ln Y=\alpha \ln K +\beta \ln L +\varepsilon\]</span></p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod1 &lt;- lm(log(vadd)~log(emp)+log(cap),data[data$year==58,])
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = log(vadd) ~ log(emp) + log(cap), data = data[data$year == 
    58, ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.72254 -0.16410 -0.02135  0.16161  1.17701 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.41898    0.06172   22.99   &lt;2e-16 ***
log(emp)     0.69748    0.01868   37.34   &lt;2e-16 ***
log(cap)     0.27609    0.01430   19.30   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.2754 on 456 degrees of freedom
Multiple R-squared:  0.9269,    Adjusted R-squared:  0.9266 
F-statistic:  2893 on 2 and 456 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<h3 id="part-b-4">Part (b)</h3>
<p>Test whether your estimates are consistent with the production function exhibiting constant returns to scale, i.e. </p>
<p><span class="math display">\[H_{0}: \alpha+\beta=1\]</span></p>
<p>against the alternative</p>
<p><span class="math display">\[H_{1}: \alpha+\beta\neq1\]</span></p>
<p>Do you reject the null hypothesis at the 5% level? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<p>What is the p-value of your test (rounded to 3 decimal places)? <input class='solveme nospaces' size='5' data-answer='["0.043"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(car)
linearHypothesis(mod1,&quot;log(emp)+log(cap)=1&quot; )</code></pre>
<pre><code>
Linear hypothesis test

Hypothesis:
log(emp)  + log(cap) = 1

Model 1: restricted model
Model 2: log(vadd) ~ log(emp) + log(cap)

  Res.Df    RSS Df Sum of Sq     F  Pr(&gt;F)  
1    457 34.892                             
2    456 34.580  1   0.31205 4.115 0.04309 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<h3 id="part-c-3">Part (c)</h3>
<p>An alternative way to test the hypothesis of constant returns to scale is to impose this restriction on the parameters and transform your regression model. Derive the necessary transformation, and show how the constant returns hypothesis amounts to a t-test in this transformed model. Carry out this test.</p>
<p>Does your result match what you found in (b)? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>If H0 is true we have that <span class="math inline">\(\beta=1-\alpha\)</span>. This means we can re-write the original equation as <span class="math display">\[\ln\frac{Y}{L}=\alpha \ln\frac{K}{L}+\varepsilon\]</span></p>
<p>Hence we can regress <span class="math inline">\(\ln\frac{Y}{L}\)</span> on <span class="math inline">\(\ln\frac{K}{L})\)</span> and <span class="math inline">\(\ln L\)</span> and do a t-test on the hypothesis that the coefficient on <span class="math inline">\(\ln L\)</span> is equal to 0:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mod2 &lt;- lm(log(vadd/emp)~log(cap/emp)+log(emp),data[data$year==58,])
summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = log(vadd/emp) ~ log(cap/emp) + log(emp), data = data[data$year == 
    58, ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.72254 -0.16410 -0.02135  0.16161  1.17701 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1.41898    0.06172  22.991   &lt;2e-16 ***
log(cap/emp)  0.27609    0.01430  19.304   &lt;2e-16 ***
log(emp)     -0.02643    0.01303  -2.029   0.0431 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.2754 on 456 degrees of freedom
Multiple R-squared:  0.4571,    Adjusted R-squared:  0.4547 
F-statistic: 191.9 on 2 and 456 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>Note that we get the same p-value as before because it is essentially the same test.</p>
</div>
<h3 id="part-d-2">Part (d)</h3>
<p>What is the average size in numbers employed across all industries in 1958? <input class='solveme nospaces' size='5' data-answer='["34000"]'/></p>
<p>Suppose an industry of average size employs an additional 1000 workers. What does the model estimated in part (a) imply about the effect this will have on value added (in percent, to 1 decimal place)? <input class='solveme nospaces' size='3' data-answer='["2.1"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  memp58 &lt;- mean(data$emp[data$year==58])
  memp58</code></pre>
<pre><code>
[1] 34.26035</code></pre>
</div>
<p>Average industry employs 34 thousand workers (note that employment is measured in thousands).</p>
<p>Adding 1000 workers to the average industry implies and increase of about 3%. Given that our estimate of β which we can interpret as an elasticity we would expect that value added increases by 3%×0.7=2.1%.</p>
</div>
<h3 id="part-e-1">Part (e)</h3>
<p>Do you think that our estimates in (a) could be biased? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select> If so, why would that be?</p>
<div class="solution">
<button>
Answer:
</button>
<p>There is concern of endogeneity with regression such as in (a). While clearly more input factors has a causal effect on outputs it is also plausible that industries which have for whatever reason a positive shock to their output might attract more workers and capital. What’s more: with more than one explanatory variable it’s no longer that easy to predict the sign of the bias because it not only depends on the relationship between the error and the dependent variable but also on the relationship between the various explanatory variables as well as the relative strength of endogeneity for different variables. For instance in the case of production function regression the suspicion is that the labour coefficient is upward biased whereas the capital coefficient is downward biased. Not because one is positively correlated with the shock and the other is negatively correlated but because labour – being a more flexible production factor – is likely to be more positively correlated with the shock than capital.</p>
</div>
<h1 id="exercise-5.7">Exercise 5.7</h1>
<p>Use the dataset attend.dta to analyze whether attending lectures has a causal effect on final exam performance. The dataset contains 674 observations on college students who took a particular course. Most variables on the dataset should be self-explanatory. The ACT is a college entry test. GPA is grade point average, the average performance in all courses.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  library(lmtest)
  library(car)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AABGEGjs2k7bZZQxU0H9SDtga/attend.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
     attend         termgpa          priGPA           ACT       
 Min.   : 2.00   Min.   :0.000   Min.   :0.857   Min.   :13.00  
 1st Qu.:24.00   1st Qu.:2.150   1st Qu.:2.200   1st Qu.:20.00  
 Median :28.00   Median :2.680   Median :2.560   Median :22.00  
 Mean   :26.28   Mean   :2.614   Mean   :2.592   Mean   :22.48  
 3rd Qu.:30.00   3rd Qu.:3.120   3rd Qu.:2.950   3rd Qu.:25.00  
 Max.   :32.00   Max.   :4.000   Max.   :3.930   Max.   :32.00  
     final          atndrte           hwrte            frosh     
 Min.   :10.00   Min.   :  6.25   Min.   : 12.50   Min.   :0.00  
 1st Qu.:22.00   1st Qu.: 75.00   1st Qu.: 87.50   1st Qu.:0.00  
 Median :26.00   Median : 87.50   Median :100.00   Median :0.00  
 Mean   :25.89   Mean   : 82.12   Mean   : 87.91   Mean   :0.23  
 3rd Qu.:29.00   3rd Qu.: 93.75   3rd Qu.:100.00   3rd Qu.:0.00  
 Max.   :39.00   Max.   :100.00   Max.   :100.00   Max.   :1.00  
      soph           skipped          stndfnl        
 Min.   :0.0000   Min.   : 0.000   Min.   :-3.30882  
 1st Qu.:0.0000   1st Qu.: 2.000   1st Qu.:-0.78782  
 Median :1.0000   Median : 4.000   Median : 0.05252  
 Mean   :0.5801   Mean   : 5.721   Mean   : 0.02914  
 3rd Qu.:1.0000   3rd Qu.: 8.000   3rd Qu.: 0.68277  
 Max.   :1.0000   Max.   :30.000   Max.   : 2.78361  </code></pre>
</div>
<h3 id="part-a-5">Part (a)</h3>
<p>Run a regression of stndfnl, the standardized final exam score, on attend, the number of lectures attended (note: the data is from the US where they call a lecture a class).</p>
<p>How much will attending one extra lecture add to the standardised final score (4 decimal places)? <input class='solveme nospaces' size='6' data-answer='["0.0278"]'/></p>
<p>Is the effect large or small? <select class='solveme' data-answer='["Quite large"]'> <option></option> <option>Quite small</option> <option>Quite large</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>Attending one extra lecture add 0.0278 to the standardized final score. In total there were 32 classes. Based on this, attending only half of those classes would imply a reduction in final outcome of 16×0.0278=0.44. This seems fairly substantial. While it is not enough to make a difference between a weak student (e.g. somebody in the bottom quartile; stndfnl=-0.78780) and a strong student (say somebody in the top quartile, stndfnl=0.68280) it has the potential to move a median student (stndfnl=0.0525) into top quartile territory (see summary stats for stndfnl below)</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod1 &lt;- lm(stndfnl~attend,data)
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4415 -0.6700 -0.0245  0.6614  2.6787 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.702364   0.192243  -3.654 0.000279 ***
attend       0.027836   0.007172   3.881 0.000114 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9824 on 672 degrees of freedom
Multiple R-squared:  0.02192,   Adjusted R-squared:  0.02047 
F-statistic: 15.06 on 1 and 672 DF,  p-value: 0.0001143</code></pre>
<pre class="r"><code>
  summary(data$stndfnl)</code></pre>
<pre><code>
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-3.30882 -0.78782  0.05252  0.02914  0.68277  2.78361 </code></pre>
<pre class="r"><code>
  mod1$coefficients[[2]]*sd(data$attend)/sd(data$stndfnl)</code></pre>
<pre><code>
[1] 0.1480643</code></pre>
</div>
</div>
<h3 id="part-b-5">Part (b)</h3>
<p>Do you think that our estimates in (a) could be biased? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<p>What would be the ideal way of addressing the problem? <select class='solveme' data-answer='["Use an instrumental variable"]'> <option></option> <option>Do a randomised controlled trial</option> <option>Include variables to control for ability/diligence</option> <option>Use an instrumental variable</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>The regression in (a) could be biased for a number of reasons. The main worry would be that students who are better irrespective of attendance are also more diligent in general and therefore more likely to attend class.</p>
<p>The best way of dealing with endogeneity in this context would be to use an instrumental variable. In absence of a good instrument (e.g. a nice instrument would be if some students where kept from attending class because of some weather or transport problem) we have to rely on the inclusion of further controls to deal which hopefully control for ability/diligence etc. of students.</p>
</div>
<h3 id="part-c-4">Part (c)</h3>
<p>Enter each of the following variables one at a time as a control in your regression: termgpa, priGPA, ACT. For each of these controls, answer the following questions:</p>
<ol type="1">
<li><p>Does entering the control variable termgpa help solve the problem you discussed in part (b) and gets you closer to a causal effect of lecture attendance? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p></li>
<li><p>Does entering the control variable priGPA create potential new problems in interpreting the coefficient on attend causally? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select> Why?</p></li>
<li><p>What happens to the coefficient on attend when you add the ACT variable? It becomes <select class='solveme' data-answer='["positive and significant"]'> <option></option> <option>negative and not significant</option> <option>negative and significant</option> <option>positive and not significant</option> <option>positive and significant</option></select>. Interpret this result.</p></li>
</ol>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mod2 &lt;- lm(stndfnl~attend+termgpa,data)
summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + termgpa, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3122 -0.5612 -0.0228  0.5745  2.3635 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -1.273935   0.166898  -7.633 7.90e-14 ***
attend      -0.035146   0.007222  -4.866 1.42e-06 ***
termgpa      0.851879   0.052597  16.196  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.8336 on 671 degrees of freedom
Multiple R-squared:  0.2968,    Adjusted R-squared:  0.2947 
F-statistic: 141.6 on 2 and 671 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>The term grade point average is strongly positive and significant and leads to a negative attendance effect. Note that the termgpa is most likely affected by higher attendance; However, by including it as a separate explanatory variable the resulting estimate ignore this effect. Instead what we are picking up is the final grade of people that attended class a lot but it did not make a difference to their term GPA. In other words these are probably very weak students who desperately tried to improve by attending classes a lot but it did not have a positive effect on either their term GPA or their final score.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mod3 &lt;- lm(stndfnl~attend+priGPA,data)
summary(mod3)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + priGPA, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4949 -0.6228 -0.0443  0.6241  2.4043 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -1.698644   0.208907  -8.131 2.06e-15 ***
attend      -0.001748   0.007425  -0.235    0.814    
priGPA       0.684353   0.072085   9.494  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9231 on 671 degrees of freedom
Multiple R-squared:  0.1377,    Adjusted R-squared:  0.1352 
F-statistic:  53.6 on 2 and 671 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>priGPA is the GPA before the term. Again, we find a strong positive relation with stndfnl which is not surprising as ability to get good (or bad) results is very persistent. Again, the attendance coefficient becomes negative although this is not significant. Unlike for termgpa we cannot argue that attendance causes priGPA as well: attendance cannot affect past grades. So perhaps this means that there is really no causal effect of attendance on final outcomes.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mod4 &lt;- lm(stndfnl~attend+ACT,data)
summary(mod4)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + ACT, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3142 -0.5702 -0.0045  0.6175  2.4836 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -3.448301   0.307065 -11.230  &lt; 2e-16 ***
attend       0.037599   0.006671   5.636 2.56e-08 ***
ACT          0.110749   0.010114  10.950  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9056 on 671 degrees of freedom
Multiple R-squared:  0.1702,    Adjusted R-squared:  0.1677 
F-statistic: 68.81 on 2 and 671 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>The college entrance results captured by ACT are another way of controlling for ability. However, including it, far from destroying the effect of attendance makes is slightly stronger. A mechanism that could explain this is as follows: far from being more diligent, the most able students might have actually somewhat of a cavalier attitude. They know they are good and they know they don’t attend class to be good. Thus if this was the only effect we expect a downward bias in the simple regression of final scores on attendance. It is plausible that ACT captures this as it is the college entrance score.</p>
</div>
<h3 id="part-d-3">Part (d)</h3>
<p>Drawing on your discussion in (c), which of the control variables termgpa, priGPA, ACT would you like to have in your regression in order to uncover the causal effect of lecture attendance? <select class='solveme' data-answer='["ACT and priGPA"]'> <option></option> <option>termgpa</option> <option>priGPA</option> <option>ACT</option> <option>termgpa and priGPA</option> <option>termgpa and ACT</option> <option>All three</option> <option>ACT and priGPA</option></select></p>
<p>Why? Run your preferred specification and think of why it’s best.</p>
<div class="solution">
<button>
Answer:
</button>
<p>In reality we will have both effects potentially causing endogeneity (diligent students attending more class and cavalier geniuses not attending class) Our best bet to control for it is by including both ACT and priGPA. However, we should not include termGPA because of the potential reverse causality. This leads to a lower effect of attendance (0.017) but it is still significant.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod5 &lt;- lm(stndfnl~attend+priGPA+ACT,data)
  summary(mod5)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + priGPA + ACT, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.2386 -0.5518 -0.0396  0.5927  2.3329 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -3.359279   0.301720 -11.134  &lt; 2e-16 ***
attend       0.017415   0.007603   2.291   0.0223 *  
priGPA       0.410436   0.078675   5.217 2.43e-07 ***
ACT          0.083060   0.011253   7.381 4.66e-13 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.8884 on 670 degrees of freedom
Multiple R-squared:  0.2026,    Adjusted R-squared:  0.199 
F-statistic: 56.74 on 3 and 670 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<h3 id="part-e-2">Part (e)</h3>
<p>Students who are diligent in attending lectures may also be more diligent about other aspects of their coursework, like completing homework. There is a variable hwrte in the dataset indicating the percentage of homework turned in. Add this variable as a regressor to your preferred specification from (d).</p>
<p>Is hwrte significant at the 5% level? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p>
<p>Is it a regressor you want in order to uncover the causal effect of lecture attendance on student performance? <select class='solveme' data-answer='["No"]'> <option></option> <option>Yes</option> <option>No</option></select></p>
<p>What happens to the coefficient on attend? <select class='solveme' data-answer='["It reduces and becomes not significant"]'> <option></option> <option>It increases and becomes significant</option> <option>It reduces and becomes significant</option> <option>It increases and becomes not significant</option> <option>It reduces and becomes not significant</option></select></p>
<p>Interpret your results.</p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod6 &lt;- lm(stndfnl~attend+priGPA+ACT+hwrte,data)
  summary(mod6)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + priGPA + ACT + hwrte, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.98362 -0.56827 -0.03468  0.60324  2.32557 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -3.471448   0.308536 -11.251  &lt; 2e-16 ***
attend       0.009107   0.009046   1.007   0.3144    
priGPA       0.400493   0.078786   5.083 4.82e-07 ***
ACT          0.083834   0.011246   7.454 2.81e-13 ***
hwrte        0.003855   0.002282   1.689   0.0917 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.8872 on 669 degrees of freedom
Multiple R-squared:  0.206, Adjusted R-squared:  0.2012 
F-statistic: 43.39 on 4 and 669 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>Including hwrte reduces the coefficient on attend and makes it not significant. However, the effect of hwrte is equally not very significant. This is likely because the two variables are very co-linear: students who attend class a lot are also more likely to do their homework diligently and so it is difficult to separately identify the effect of the two.</p>
<p>It is easy to imagine a situation where knowing them separately would be useful: Suppose a teacher is trying to figure out if it would be more useful to give another lecture or instead set another homework. Equally, it might not important or even outright wrong to try to distinguish the two; e.g. suppose a teacher wants to work out the effect of introducing sanctions (i.e. a negative participation grade) for not attending lectures. Part of the mechanism from more lecture to better grades might a positive effect on homework as well (e.g. students might be less forgetful about homework or they might be worried about looking bad in class). This causal effect of attendance would be ignored in a joint regression.</p>
</div>
<h3 id="part-f-1">Part (f)</h3>
<p>There is a variable skipped in the dataset indicating the number of skipped lectures. Add this variable as a regressor to your preferred specification from (d).</p>
<p>What happens and why? It becomes <select class='solveme' data-answer='["none of the above because it is perfectly collinear with attend"]'> <option></option> <option>negative and not significant</option> <option>negative and significant</option> <option>positive and not significant</option> <option>positive and significant</option> <option>none of the above because it is perfectly collinear with attend</option></select>. Interpret this result.</p>
<div class="solution">
<button>
Answer:
</button>
<p>“skipped” is perfectly collinear with “attend”</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod7 &lt;- lm(stndfnl~attend+priGPA+ACT+hwrte+skipped,data)
  summary(mod7)</code></pre>
<pre><code>
Call:
lm(formula = stndfnl ~ attend + priGPA + ACT + hwrte + skipped, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.98362 -0.56827 -0.03468  0.60324  2.32557 

Coefficients: (1 not defined because of singularities)
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -3.471448   0.308536 -11.251  &lt; 2e-16 ***
attend       0.009107   0.009046   1.007   0.3144    
priGPA       0.400493   0.078786   5.083 4.82e-07 ***
ACT          0.083834   0.011246   7.454 2.81e-13 ***
hwrte        0.003855   0.002282   1.689   0.0917 .  
skipped            NA         NA      NA       NA    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.8872 on 669 degrees of freedom
Multiple R-squared:  0.206, Adjusted R-squared:  0.2012 
F-statistic: 43.39 on 4 and 669 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<h1 id="exercise-5.8">Exercise 5.8</h1>
<p>Download the data TeachingRatings.dta. This data set contains data on the teaching evaluations of 463 professors at the University of Texas, and various attributes of the professor and course.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  library(foreign)
  library(lmtest)
  data &lt;- read.dta(&quot;https://www.dropbox.com/sh/rqmo1hvij1veff0/AACPj9dkKUrGIGji8Ar8nEPla/TeachingRatings.dta?dl=1&quot;)
  summary(data)</code></pre>
<pre><code>
    minority           age            female         onecredit      
 Min.   :0.0000   Min.   :29.00   Min.   :0.0000   Min.   :0.00000  
 1st Qu.:0.0000   1st Qu.:42.00   1st Qu.:0.0000   1st Qu.:0.00000  
 Median :0.0000   Median :48.00   Median :0.0000   Median :0.00000  
 Mean   :0.1382   Mean   :48.37   Mean   :0.4212   Mean   :0.05832  
 3rd Qu.:0.0000   3rd Qu.:57.00   3rd Qu.:1.0000   3rd Qu.:0.00000  
 Max.   :1.0000   Max.   :73.00   Max.   :1.0000   Max.   :1.00000  
     beauty          course_eval        intro       
 Min.   :-1.45049   Min.   :2.100   Min.   :0.0000  
 1st Qu.:-0.65627   1st Qu.:3.600   1st Qu.:0.0000  
 Median :-0.06801   Median :4.000   Median :0.0000  
 Mean   : 0.00000   Mean   :3.998   Mean   :0.3391  
 3rd Qu.: 0.54560   3rd Qu.:4.400   3rd Qu.:1.0000  
 Max.   : 1.97002   Max.   :5.000   Max.   :1.0000  
   nnenglish      
 Min.   :0.00000  
 1st Qu.:0.00000  
 Median :0.00000  
 Mean   :0.06048  
 3rd Qu.:0.00000  
 Max.   :1.00000  </code></pre>
</div>
<h3 id="part-a-6">Part (a)</h3>
<p>Run a regression of course_eval on beauty. Beauty is an index that was based on a subjective scoring.</p>
<p>What is the slope coefficient of the regression? <input class='solveme nospaces' size='5' data-answer='["0.133"]'/></p>
<div class="solution">
<button>
Answer:
</button>
<p>We get a slope coefficient of 0.133.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod1 &lt;- lm(course_eval~beauty,data)
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = course_eval ~ beauty, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.80015 -0.36304  0.07254  0.40207  1.10373 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  3.99827    0.02535 157.727  &lt; 2e-16 ***
beauty       0.13300    0.03218   4.133 4.25e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.5455 on 461 degrees of freedom
Multiple R-squared:  0.03574,   Adjusted R-squared:  0.03364 
F-statistic: 17.08 on 1 and 461 DF,  p-value: 4.247e-05</code></pre>
</div>
</div>
<h3 id="part-b-6">Part (b)</h3>
<p>The number in (a) will not have much meaning to anyone who doesn’t know anything about the data.</p>
<p>Is the effect of beauty on course_eval big or small? How would you go about assessing this?</p>
<div class="solution">
<button>
Answer:
</button>
<p>To understand if something is big or small we need to have some sort of benchmark to compare it to. If you lack other obvious benchmarks, we can always what happends in response to a reasonable change in the explanatory variable to a reasonable change in the dependent variable. For instance we could see what happens if we change the <code>beauty</code> variable by 1 standard deviation (sd(data$beauty= 0.789)) (of the beauty variable). The coefficient above suggest that this would lead to a change of 0.133 <span class="math inline">\(\times\)</span> 0.789 = 0.105.</p>
<p>Is this big? Well depends in part on how much the dependent variable usually changes; e.g. we can look at the change of standard deviation of the dependent variable as well, which is 0.555. Hence, the beauty effect would amount of 18.904% of the evaluation standard deviation. Seems quite a lot for something that seems to not exactly relevant to learning. But of course that depends a bit on the eye of the beholder. Of course we could understand very well if some of you only came to university to enjoy the physical beauty of your lecturers.</p>
<p>As an alternative we can look at the change in the inter-quartile (i.e. the difference between the 75th and 25th percentile) range in beauty and see how that compares to the inter-quartile range in course scores:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  a=mod1$coefficients[[2]]*(quantile(data$beauty,0.75)[[1]]-quantile(data$beauty,0.25)[[1]])
  b=(quantile(data$course_eval,0.75)[[1]]-quantile(data$course_eval,0.25)[[1]])
  
  a/b</code></pre>
<pre><code>
[1] 0.1998132</code></pre>
</div>
<p>i.e. gives us a very similar answer.</p>
</div>
<h3 id="part-c-5">Part (c)</h3>
<p>Is the slope coefficient in (a) statistically significantly different from zero? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<div class="solution">
<button>
Answer:
</button>
<p>We get a significant slope coefficient.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod1 &lt;- lm(course_eval~beauty,data)
  summary(mod1)</code></pre>
<pre><code>
Call:
lm(formula = course_eval ~ beauty, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.80015 -0.36304  0.07254  0.40207  1.10373 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  3.99827    0.02535 157.727  &lt; 2e-16 ***
beauty       0.13300    0.03218   4.133 4.25e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.5455 on 461 degrees of freedom
Multiple R-squared:  0.03574,   Adjusted R-squared:  0.03364 
F-statistic: 17.08 on 1 and 461 DF,  p-value: 4.247e-05</code></pre>
</div>
</div>
<h3 id="part-d-4">Part (d)</h3>
<p>Run a regression of course_eval on beauty and female. Did the coefficient on beauty become bigger or smaller? <select class='solveme' data-answer='["Bigger"]'> <option></option> <option>Smaller</option> <option>Bigger</option></select></p>
<p>How would you explain this?</p>
<div class="solution">
<button>
Answer:
</button>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
  mod2 &lt;- lm(course_eval~beauty+female,data)
  summary(mod2)</code></pre>
<pre><code>
Call:
lm(formula = course_eval ~ beauty + female, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.87197 -0.36913  0.03493  0.39919  1.03237 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.08158    0.03293  123.94  &lt; 2e-16 ***
beauty       0.14859    0.03195    4.65 4.34e-06 ***
female      -0.19781    0.05098   -3.88  0.00012 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.5373 on 460 degrees of freedom
Multiple R-squared:  0.0663,    Adjusted R-squared:  0.06224 
F-statistic: 16.33 on 2 and 460 DF,  p-value: 1.407e-07</code></pre>
</div>
<p>The beauty coefficient becomes a bit bigger (0.149). This is because it seems that women tend to get lower teaching but higher beauty scores.</p>
</div>
<h3 id="part-e-3">Part (e)</h3>
<p>What is the <span class="math inline">\(R^{2}\)</span> of the regression in (d)? <input class='solveme nospaces' size='6' data-answer='["0.0663"]'/></p>
<p>Does it increase or decrease compared to the regression which does not include female? <select class='solveme' data-answer='["Increase"]'> <option></option> <option>Decrease</option> <option>Increase</option></select></p>
<p>Think why that could be.</p>
<div class="solution">
<button>
Answer:
</button>
<p><span class="math inline">\(R^{2}\)</span> goes from 0.0357 to 0.0663. Adding more variables will always increase the <span class="math inline">\(R^{2}\)</span> .</p>
</div>
<h3 id="part-f-2">Part (f)</h3>
<p>Is it possible that even in this case, the interpretation of the effect of beauty might not necessarily be causal? <select class='solveme' data-answer='["Yes"]'> <option></option> <option>No</option> <option>Yes</option></select></p>
<p>Think of why.</p>
<div class='solution'>
<button>
Answer:
</button>
<p>As usual we have to consider confounding factors. It’s not immediately clear why other factors driving good teaching could have a reverse causality on teaching. But here is one story: beauty is of course a very subjective measure. We perceive people who are well dressed as more beautiful. Perhaps the same factors that make a person dress well are also useful when teaching (e.g. lecture slides are more tidy). Hence, when we just consider beauty we may in part pick up the effect of tidier lecture slides.</p>
<p>`r unhide()</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<script>

/* update total correct if #total_correct exists */
update_total_correct = function() {
  if (t = document.getElementById("total_correct")) {
    t.innerHTML =
      document.getElementsByClassName("correct").length + " of " +
      document.getElementsByClassName("solveme").length + " correct";
  }
}

/* solution button toggling function */
b_func = function() {
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "");
  }
  
  if (my_answer !== "" & real_answers.includes(my_answer)) {
    cl.add("correct");
  } else {
    cl.remove("correct");
  }
  update_total_correct();
}

window.onload = function() {
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('solution')) {
      buttons[i].onclick = b_func;
    }
  }
  
  /* set up solveme inputs */
  var solveme = document.getElementsByClassName("solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off"); 
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";
    
    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;
    
    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  update_total_correct();
}

</script>
<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Martin (2020, Nov. 23). Datastories Hub: Exercises 5. Retrieved from https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{martin2020exercises,
  author = {Martin, Ralf},
  title = {Datastories Hub: Exercises 5},
  url = {https://mondpanther.github.io/datastorieshub/posts/exercises/exercises5/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
