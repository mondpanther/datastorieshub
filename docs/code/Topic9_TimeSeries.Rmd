---
title: "Time Series"
author: Ralf Martin
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r get weekly covid data for us}
library(dplyr)
library(lubridate)
nyt <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"))
nyt=nyt%>%mutate(date=as.character(date))
maxt=max(nyt$date)
nytmax=nyt%>% filter(date==maxt)
covidus=nyt %>% group_by(date) %>% summarise_at(vars(cases,deaths),sum)

start.date = ymd_hms("2008-01-05 00:00:00")
end.date   = as_datetime(now()) #ymd_hms("2020-04-02 01:00:00")
#end.date   = ymd_hms("2020-04-04 01:00:00")
breaks = seq(start.date, end.date, "1 week")

covidus = covidus %>% mutate(date=as_datetime(date),
                             week=cut(date, breaks=breaks)) %>% 
          group_by(week) %>%  
          summarise_at(vars(cases,deaths),max)


wei=read.csv("https://www.dropbox.com/s/d4h50imfkvmo2la/weekly-economic-index_data.csv?dl=1") %>% 
    rename(week=Date)
    #mutate(week=as.character(as_date(Date)))  
    #mutate(week=gsub("/","-",Date))

df=wei %>%  left_join(covidus, by="week") %>%  
   mutate(week=as_date(week),cases=replace(deaths,is.na(cases),0),
                  deaths=replace(deaths,is.na(deaths),0),lnindex=log(Index)) 




```

```{r}
library(ggplot2)
library(scales)
scaler=max(df$cases,na.rm=TRUE)/max(df$Index,na.rm=TRUE)
  
ggplot(df,aes(x=week)) + theme_minimal() + xlab("Weekly Data") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_x_date(breaks = date_breaks("12 months"),labels = date_format("%Y")) +
  geom_line(aes(y = Index*scaler, colour = "Economic Activity Index"))+
  geom_line(aes(y = cases, colour = "Covid Cases"))+
  scale_y_continuous(sec.axis = sec_axis(label=comma, trans=~./(scaler),
                     name = "Number of cases"),labels=comma)




```


```{r}

lm(lnindex~cases,df) %>% summary()
df=df %>% mutate(t=1:n())
lm(lnindex~cases+t,df) %>% summary()
lm(Index~cases+t,df,year(week)>2018) %>% summary()



  library(urca)
  
  dickey=ur.df(df$cases,type="trend",lags=1)
  summary(dickey)

  dickey=ur.df(df$lnindex,type="trend",lags=0)
  summary(dickey)
  
  
  
  df=df %>% arrange(week) %>% mutate(Dlnindex=lnindex-lag(lnindex),
                                     Dcases=cases-lag(cases) ,
                                     DDlnindex=Dlnindex-lag(Dlnindex))
  ggplot(df,aes(x=week,y=Dlnindex))+geom_line()
  
  dickey=ur.df(diff(df$cases,1),type="trend",lags=1)
  summary(dickey)

  dickey=ur.df(diff(df$index,1),type="trend",lags=3)
  summary(dickey)
  
  
  dickey=ur.df(diff(diff(df$lnindex,1)),type="trend",lags=3)
  summary(dickey)
  
  dickey=ur.df(df$lnindex,type="drift")
  summary(dickey)
  
  dickey=ur.df(df$lnindex,type="trend")
  summary(dickey)
  
  dickey=ur.df(diff(df$lnindex,1))
  summary(dickey)
  
  
    
```


```{r}
# Time Series

#< load libraries
  library(foreign)
  
  
#>


#< Set working directory
  setwd("/Users/ralfmartin/research/Dropbox/teaching/ClimateQuant2016/R")
#>

#< GDP Japan
  library(haven)
  gdpjp <-read_dta("data/gdp_JP_etc.dta")
  library(zoo)
  library(DataCombine)
  library(quantmod)
  library(tseries)
  
  
  gdpjp["L1lngdp"]=Lag(gdpjp$lngdp,1)
  
  
  gdpjp["L1lngdp"]=Lag(gdpjp$lngdp,1)
  
  summary(lm(lngdp~L1lngdp ,gdpjp))
  summary(arma(gdpjp$lngdp, order = c(1, 0)))
  
  summary(arma(gdpjp$lngdp, order = c(2, 0)))
  
  
  
  summary(lm(lngdp~L1lngdp+time ,gdpjp))
  
  gdpjp["Dlngdp"]<-c(NA,diff(gdpjp$lngdp, differences=1))
#>
  
#< Dickey Fuller
  library(urca)
  
  df=ur.df(gdpjp$lngdp,type="trend",lags=0)
  summary(df)
 
  summary(ur.df(diff(gdpjp$lngdp,1),type="trend",lags=0))
  
  summary(ur.df(diff(gdpjp$lngdp,1),type="trend",lags=1))
  
  
  summary(ur.df(gdpjp$lngdp,type="trend",lags=1))
  summary(ur.df(gdpjp$lngdp,type="trend",lags=5))
  summary(ur.df(gdpjp$lngdp,type="trend",lags=3))
  
  summary(ur.df(diff(gdpjp$lngdp,1),type="trend",lags=3))
  
  

#>
#< Oragne juice
  
  oj <-read_dta("data/oj.dta")  
  oj = na.omit(oj)
  oj["lnp"]=log(oj$ppioj/oj$pwfsa *100)
  
  
  summary(ur.df(oj$fdd,type="trend",lags=12))
  
  summary(ur.df(oj$lnp,type="trend",lags=12))
  summary(ur.df(diff(oj$lnp,1),type="trend",lags=12))

  
  summary(lm(diff(oj$lnp,1)~oj$fdd[-1]))
  
  
  
  ojm=lm(diff(oj$lnp)~oj$fdd[-1])
  library(sandwich)
  library(lmtest)
  coeftest(ojm, vcov. = NeweyWest)
  
#>  
  
```
