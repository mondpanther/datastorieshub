---
title: "Exercises 4"
description: |
  Testing your knowledge of testing
author:
  - name: Ralf Martin
    url: https://mondpanther.github.io/wwwmondpanther/
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    self_contained: true
    css: ../../webex.css
    includes:
      after_body: ../../webex.js
categories:
  - Exercises
editor_options: 
  chunk_output_type: inline
---


```{r setup, include = FALSE, message=FALSE}
library("webex")
library(ggplot2)
knitr::opts_chunk$set(fig.path='../../../images/')
knitr::opts_chunk$set(echo=TRUE)


part=function(reset=FALSE){
  if(reset){ pp <<- 0}
  pp <<- pp+1
  rr=letters[pp]
  
  return(rr)
}

part(TRUE)
part()

```



# Exercise 4.1

A researcher hypothesizes that year of schooling, S, may be related to the number of siblings (brothers and sisters) one has, SIBLINGS, according to the relationship `r $$S = \beta_{1}+\beta_{2}SIBLINGS+\epsilon$$`

She is prepared to test the null hypothesis `r  $H0: \beta_{2}=0$` against the alternative hypothesis `r  $H1: \beta_{2}=0 beta_{2}\neq 0 $` at the 5 and 1 percent levels. She has a sample of 60 observations. What are the t-distribution values and what will she conclude in the following cases?


### Part (`r part(TRUE)`)  
If `r  $\hat{\beta}_{2} = -0.20, \sigma_{hat{\beta}_{2}}=0.07$`?

The t-value (rounded up to 3 decimal places) is: `r fitb(-2.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", "No", answer = "Yes"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("Yes", "No", answer = "Yes"))`


### Part (`r part()`)
If `r  $\hat{\beta}_{2} = -0.12, \sigma_{hat{\beta}_{2}}=0.07$`?

The t-value (rounded up to 3 decimal places) is: `r fitb(-1.714)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", "No", answer = "No"))`

Can she reject H0 at at the 1% significance level)? `r mcq(c("Yes", "No", answer = "No"))`


### Part (`r part()`)
If `r  $\hat{\beta}_{2} = 0.06, \sigma_{hat{\beta}_{2}}=0.07$`?

The t-value (rounded up to 3 decimal places) is: `r fitb(0.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", "No", answer = "No"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("Yes", "No", answer = "No"))`


### Part (`r part()`)
If `r  $\hat{\beta}_{2} = 0.20, \sigma_{hat{\beta}_{2}}=0.07$`?

The t-value (rounded up to 3 decimal places) is: `r fitb(2.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", "No", answer = "Yes"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("Yes", "No", answer = "Yes"))`


`r hide("Hint:")`
Recall that the rejection threshold c for the normal distribution are `r abs(qnorm(0.025))` and `r abs(qnorm(0.005))` for a 5% and 1% significance level.
For the t distribution the same values are `r abs(qt(0.025,58))` and `r abs(qt(0.005,58))` (Note that we have 58 degrees of freedom).

We can also work out p-values
```{r}
  pt(abs(-0.2)/0.07,58)
  pt(abs(-0.12)/0.07,58)
  pt(0.06/0.07,58)
  pt(0.20/0.07,58)
```
`r unhide()`

`r hide("Answer:")`
```{r, echo = TRUE}

Hence we get the following answers

1.	t=-0.2/0.07=-2.857
Significantly different from 0 at 5 and 1 percent; i.e. we reject the H0 at either significance level.

2.	t=-0.12/0.07=-1.714
Not significantly different from 0 at 5 and 1 percent; i.e. we don't reject the H0

3.	t=0.06/0.07=0.857
Not significantly different from 0 at 5 and 1 percent.

4.	t=0.2/0.07=2.857
Significantly different from 0 at 5 and 1 percent; i.e. we reject the H0 at either significance level.

```
`r unhide()`
  
    
# Exercise 4.2

Lets use the WAGE1.DTA dataset again!

```{r, echo = TRUE}  
  library(foreign)
  data <- read.dta("https://www.dropbox.com/sh/rqmo1hvij1veff0/AADZ4MZhDDk9R8sFSjBvmcRma/WAGE1.DTA?dl=1") 
```

### Part (`r part()`)

Regress wages on education (years of schooling). Perform a test of the hypothesis that the coefficient on schooling is equal to 0. 

Can you reject the hypothesis? `r mcq(c("Yes", "No", answer = "Yes"))`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod <- lm(wage~educ,data)
  summary(mod)
```  

i.e. t>2 and P very close to 0. Hence coefficient on education is highly significant (we can reject hypothesis that it is equal to 0)

`r unhide()`
  


### Part (`r part()`)
Regress tenure (years with current employer) on education. Can you think of a causal mechanism that could support this specificiation?

Can you reject the hypothesis? `r mcq(c("Yes", "No", answer = "No"))`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod2 <- lm(tenure~educ,data)
  summary(mod2)
```

i.e. there is a negative relationship: one year of extra education reduces tenure by 0.14 years. That said: this is not a significant relationship.

One reason why education might lead less tenure is that time is finite and being in education allows for less time to work on a job. Also: we are dealing here with time spend with the same employer. So it could be that employees that are more educated tend to change jobs more often (they might have more general skills that are in high demand by various employers). As a consequence they accumulate less time with a specific employer.

`r unhide()`



# Exercise 4.3

Lets go back to the auto dataset.

```{r, echo = TRUE}  
  library(foreign)
  data <- read.dta("https://www.dropbox.com/sh/rqmo1hvij1veff0/AACNkMy47ilXAMh3nmiIs_Bqa/auto.dta?dl=1")
```

### Part (`r part()`)
Draw a scatterplot of price versus weight. 
Which cars, in terms of weight, tend to be more expensive? `r mcq(c("Heavier", "Lighter", answer = "Heavier"))`


```{r}

`r hide("Answer:")`
```{r, echo = TRUE}
  plot(data$weight,data$price)
```

Heavier cars tend to be more expensive.

`r unhide()`

### Part (`r part()`)
Run a regression of price on weight. 

What is the constant? `r fitb(-6.7074)`

What is the slope coefficient? `r fitb(2.0441)`

`r hide("Answer:")`
```{r, echo = TRUE}

  mod<-lm(price~weight,data)
  summary(mod)
```
`r unhide()`

### Part (`r part()`)
What is the predicted price of a car weighing 2,500lb? `r fitb(5103.449)`
What is the predicted price of a car weighing 2,500lb? `r fitb(8169.543)`

`r hide("Answer:")`
```{r, echo = TRUE}
  value_to_forecast <- data.frame(weight=c(2500,4000))
  forecast <- predict(mod,value_to_forecast)
```  
  
Alternatively:
```{r, echo = TRUE}
  mod$coefficients[[1]]+mod$coefficients[[2]]*2500
  mod$coefficients[[1]]+mod$coefficients[[2]]*4000
```
`r unhide()`

### Part (`r part()`)
What is the expected price difference between two cars, one of which is 500kg(!) heavier?`r fitb(2252.557)`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod$coefficients[[2]]*1102
```
`r unhide()`

### Part (`r part()`)
What is the predicted price of a car weighing 500lb?`r fitb(1015.324)`

Do you think this number is very meaningful? `r mcq(c("Yes", "No", answer = "No"))`

Why or why not? Check answer below to see if you're right. 

`r hide("Answer:")`
```{r, echo = TRUE}
  mod$coefficients[[1]]+mod$coefficients[[2]]*500
```  
The lightest car in the sample weighs 1760lb. It is unlikely to tell us much about a car weighing 500lb. 
 
`r unhide()`


# Exercise 4.4

Conduct another Monter-Carlo expercise as in the previous exercise session (exercise session 2.3). Generate the $\epsilon$ shocks as before. For the X, however, use the following command: x=unif(obs)*eps.

Otherwise take the same steps as in the previous Monte Carlo exercise, using the the same true model $Y=2+0.5 X +\epsilon$. Produce a histogram to visualise your betas. 

[PS NOTE: I think the question doesn't really work like that, need to maybe edit or provide hints?...]

### Part (`r part()`)
What average estimate for the coefficient associated with X do you find now? (Round up to the nearest whole number) `r fitb(2)`


### Part (`r part()`)
How does it relate to the true value of the coefficient of 0.5, is it larger or smaller? `r mcq(c("Larger", "Smaller", answer = "Larger"))`

`r hide("Answer:")`
```{r, echo = TRUE}

    obs <- 100
    eps <- rnorm(obs)
    x <- runif(obs)*eps
    
    cor(x,eps)  # Note that x and eps will be highly positively correlated
    
    y <- 2+0.5*x+eps
    mod<-lm(y~x)
    summary(mod)
    
```


```{r}  


  beta <- double(1000)
  
  cc = double(1000)
  
  for(i in 1:1000){
    eps <- rnorm(obs)
    x <- runif(obs)  *eps
    
    
    
    y <- 2 + 0.5*x+eps
    mod<-lm(y~x)
    beta[i]<-mod$coefficients[[2]]
    
    
    cc[i]=cor(x,eps)
  }
  
  hist(beta,50)
  mean(beta)
  mean(cc)
```  

i.e. the mean of beta is much larger than 0.5  
  
`r unhide()`
