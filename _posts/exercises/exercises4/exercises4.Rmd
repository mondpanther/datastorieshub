---
title: "Exercises 4"
description: |
  Testing your knowledge of testing
author:
  - name: Ralf Martin
    url: https://mondpanther.github.io/wwwmondpanther/
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    self_contained: false
#    css: ../../webex.css
#    includes:
#      after_body: ../../webex.js
categories:
  - Exercises
editor_options: 
  chunk_output_type: inline
---

<script src="https://hypothes.is/embed.js" async></script>

```{r  fig.width=30,echo=F,preview=TRUE,out.width = '80%'}
knitr::include_graphics("selfservicetest.png")
```




```{r setup, include = FALSE, message=FALSE}
library(webexercises)
library(ggplot2)
knitr::opts_chunk$set(fig.path='../../../images/')
knitr::opts_chunk$set(echo=FALSE)


part=function(reset=FALSE){
  if(reset){ pp <<- 0}
  pp <<- pp+1
  rr=letters[pp]
  
  return(rr)
}

part(TRUE)
part()

```



# Exercise 4.1

A researcher hypothesizes that year of schooling, S, may be related to the number of siblings (brothers and sisters) one has, SIBLINGS, according to the relationship $$S = \beta_{1}+\beta_{2}SIBLINGS+\epsilon$$

She is prepared to test the null hypothesis $H0: \beta_{2}=0$ against the alternative hypothesis $H1: \beta_{2}\neq 0$ at the 5 and 1 percent levels. She has a sample of 60 observations. What are the t-distribution values and what will she conclude in the following cases?


### Part (a)
If $\hat{\beta}_{2} = -0.20, \sigma_{\hat{\beta}_{2}}=0.07$?

The t-value (rounded up to 3 decimal places) is:   `r fitb(-2.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("No", answer = "Yes"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("No", answer = "Yes"))`


### Part (b)
If $\hat{\beta}_{2} = -0.12, \sigma_{\hat{\beta}_{2}}=0.07$?

The t-value (rounded up to 3 decimal places) is: `r fitb(-1.714)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", answer = "No"))`

Can she reject H0 at at the 1% significance level)? `r mcq(c("Yes", answer = "No"))`


### Part (c)
If $\hat{\beta}_{2} = 0.06, \sigma_{\hat{\beta}_{2}}=0.07$?

The t-value (rounded up to 3 decimal places) is: `r fitb(0.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("Yes", answer = "No"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("Yes", answer = "No"))`


### Part (d)
If $\hat{\beta}_{2} = 0.20, \sigma_{\hat{\beta}_{2}}=0.07$?

The t-value (rounded up to 3 decimal places) is: `r fitb(2.857)`

Can she reject H0 at at the 5% significance level? `r mcq(c("No", answer = "Yes"))`

Can she reject H0 at at the 1% significance level? `r mcq(c("No", answer = "Yes"))`


`r hide("Hint:")`
Recall that the rejection threshold c for the normal distribution are `r abs(qnorm(0.025))` and `r abs(qnorm(0.005))` for a 5% and 1% significance level.
For the t distribution the same values are `r abs(qt(0.025,58))` and `r abs(qt(0.005,58))` (Note that we have 58 degrees of freedom).

We can also work out p-values. Remember that the p-value is the probability - assuming the H0 is correct - to have a value more extreme (further away from 0) than the one estimated. We can use the `pt()` command for that,
which gives us the cumulative density function of the t-distribution; e.g. `pt(0,58)` gives us the probability to have a value smaller than 0. Because the t-distribution is symmetric that will always be equal to 0.5
Note that we have 58 degrees of freedom here as we 60 observations and we need to estimate 2 parameters ($\beta_0$ and $\beta_1$). To work out the p-value call the `pt()` function with the t-value for a given 
estimate; e.g. for part a)
```{r}
pt(-.2/0.07,58)
```
i.e. the probability of having an estimate lower than -.2 is `r pt(-.2/0.07,58)`. Note, because the our test considers the possibility of being to low and too high (and because the distribution is symmetric) we need to double this to get the actual p-value which becomes `r 2*pt(-.2/0.07,58)`. However, this is still below 1% so we can safely reject the hypothesis that the true parameter is 0.
Note, if we estimate a positive value we still need to use the same value but in negative terms. So, more generally we could write that we need compute `2*pt(-abs(t),58)`; i.e. the negative of the absolute value 
of the t-value. Because `pt()` (like any cumulative density) sums to 1 and is symmetric and alterive formula with the same result would be `2*(1-pt(-abs(t),58))`  

```
`r unhide()`

`r hide("Answer:")`

Hence we get the following answers

1.	t=-0.2/0.07= -2.857
Significantly different from 0 at 5 and 1 percent; i.e. we reject the H0 at either significance level.

2.	t=-0.12/0.07= -1.714
Not significantly different from 0 at 5 and 1 percent; i.e. we don't reject the H0

3.	t=0.06/0.07= 0.857
Not significantly different from 0 at 5 and 1 percent.

4.	t=0.2/0.07= 2.857
Significantly different from 0 at 5 and 1 percent; i.e. we reject the H0 at either significance level.

`r unhide()`
  
    
# Exercise 4.2

Lets use the WAGE1.DTA dataset again!

```{r, echo = TRUE}  
  library(foreign)
  data <- read.dta("https://www.dropbox.com/sh/rqmo1hvij1veff0/AADZ4MZhDDk9R8sFSjBvmcRma/WAGE1.DTA?dl=1") 
```

### Part (a)

Regress wages on education (years of schooling). Perform a test of the hypothesis that the coefficient on schooling is equal to 0. 

Can you reject the hypothesis? `r mcq(c("Yes", answer = "Yes"))`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod <- lm(wage~educ,data)
  summary(mod)
```  

i.e. t>2 and P very close to 0. Hence coefficient on education is highly significant (we can reject hypothesis that it is equal to 0).

`r unhide()`
  


### Part (b)
Regress tenure (years with current employer) on education. Can you think of a causal mechanism that could support this specificiation?

Can you reject the hypothesis? `r mcq(c("Yes", answer = "No"))`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod2 <- lm(tenure~educ,data)
  summary(mod2)
```

i.e. there is a negative relationship: one year of extra education reduces tenure by 0.14 years. That said: this is not a significant relationship.

One reason why education might lead less tenure is that time is finite and being in education allows for less time to work on a job. Also: we are dealing here with time spend with the same employer. So it could be that employees that are more educated tend to change jobs more often (they might have more general skills that are in high demand by various employers). As a consequence they accumulate less time with a specific employer.

`r unhide()`



# Exercise 4.3

Lets go back to the auto dataset.

```{r, echo = TRUE}  
  library(foreign)
  data <- read.dta("https://www.dropbox.com/sh/rqmo1hvij1veff0/AACNkMy47ilXAMh3nmiIs_Bqa/auto.dta?dl=1")
```

### Part (a)
Draw a scatterplot of price versus weight. 
Which cars, in terms of weight, tend to be more expensive? `r mcq(c("Lighter", answer = "Heavier"))`


`r hide("Answer:")`
```{r, echo = TRUE}
  library(ggplot2)
  ggplot(data, aes(x=price, y=weight)) + geom_point()
```

Heavier cars tend to be more expensive.

`r unhide()`

### Part (b)
Run a regression of price on weight. 

What is the constant? `r fitb(-6.7074)`

What is the slope coefficient? `r fitb(2.0441)`

`r hide("Answer:")`
```{r, echo = TRUE}

  mod<-lm(price~weight,data)
  summary(mod)
```
`r unhide()`

### Part (c)
What is the predicted price of a car weighing 2,500lb?  `r fitb(5103.449)`

What is the predicted price of a car weighing 2,500lb?  `r fitb(8169.543)`

`r hide("Answer:")`
```{r, echo = TRUE}
  value_to_forecast <- data.frame(weight=c(2500,4000))
  forecast <- predict(mod,value_to_forecast)
```  
  
Alternatively:
```{r, echo = TRUE}
  mod$coefficients[[1]]+mod$coefficients[[2]]*2500
  mod$coefficients[[1]]+mod$coefficients[[2]]*4000
```
`r unhide()`

### Part (d)
What is the expected price difference between two cars, one of which is 500kg(!) heavier? `r fitb(2252.557)`

`r hide("Answer:")`
```{r, echo = TRUE}
  mod$coefficients[[2]]*1102
```
`r unhide()`

### Part (e)
What is the predicted price of a car weighing 500lb?  `r fitb(1015.324)`

Do you think this number is very meaningful? `r mcq(c("Yes", answer = "No"))`

Why or why not? Check the answer below to see if you're right. 

`r hide("Answer:")`
```{r, echo = TRUE}
  mod$coefficients[[1]]+mod$coefficients[[2]]*500
```  
The lightest car in the sample weighs 1760lb. It is unlikely to tell us much about a car weighing 500lb. 
 
`r unhide()`


# Exercise 4.4

Conduct another Monter-Carlo expercise as in the previous exercise session (exercise session 2.3). Generate the $\epsilon$ shocks as before. For the X, however, use the following command instead: x=unif(obs)*eps.

Otherwise take the same steps as in the previous Monte Carlo exercise, using the the same true model $Y=2+0.5 X +\epsilon$. Produce a histogram to visualise your betas. 

### Part (a)
What average estimate for the coefficient associated with X do you find now? (Round up to the nearest whole number) `r fitb(2)`


### Part (b)
How does it relate to the true value of the coefficient of 0.5, is it larger or smaller? `r mcq(c("Smaller", answer = "Larger"))`

`r hide("Answer:")`
```{r, echo = TRUE}

    obs <- 100
    eps <- rnorm(obs)
    x <- runif(obs)*eps
    
    cor(x,eps)  # Note that x and eps will be highly positively correlated
    
    y <- 2+0.5*x+eps
    mod<-lm(y~x)
    summary(mod)
    
```


```{r}  

  beta <- double(1000)
  
  cc = double(1000)
  
  for(i in 1:1000){
    eps <- rnorm(obs)
    x <- runif(obs)  *eps
    
    
    
    y <- 2 + 0.5*x+eps
    mod<-lm(y~x)
    beta[i]<-mod$coefficients[[2]]
    
    
    cc[i]=cor(x,eps)
  }
  
  hist(beta,50)
  mean(beta)
  mean(cc)
```  

i.e. the mean of beta is much larger than 0.5  
  
`r unhide()`
